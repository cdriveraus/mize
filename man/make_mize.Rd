% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mize.R
\name{make_mize}
\alias{make_mize}
\title{Create an Optimizer}
\usage{
make_mize(method = "L-BFGS", norm_direction = FALSE, scale_hess = TRUE,
  memory = 5, cg_update = "PR+", nest_q = 0, nest_convex_approx = FALSE,
  nest_burn_in = 0, use_nest_mu_zero = FALSE, step_up = 1.1,
  step_up_fun = c("*", "+"), step_down = 0.5, dbd_weight = 0.1,
  line_search = "More-Thuente", c1 = 1e-04, c2 = NULL, step0 = NULL,
  step_next_init = NULL, try_newton_step = NULL, ls_max_fn = Inf,
  ls_max_gr = Inf, ls_max_fg = Inf, mom_type = NULL,
  mom_schedule = NULL, mom_init = NULL, mom_final = NULL,
  mom_switch_iter = NULL, mom_linear_weight = FALSE, max_iter = NULL,
  restart = NULL, restart_wait = 10, par = NULL, fg = NULL)
}
\arguments{
\item{method}{Optimization method. See 'Details' of \code{\link{mize}}.}

\item{norm_direction}{If \code{TRUE}, then the steepest descent direction
is normalized to unit length. Useful for adaptive step size methods where
the previous step size is used to initialize the next iteration.}

\item{scale_hess}{if \code{TRUE}, the approximation to the inverse Hessian
is scaled according to the method described by Nocedal and Wright
(approximating an eigenvalue). Applies only to the methods \code{BFGS}
(where the scaling is applied only during the first step) and \code{L-BFGS}
(where the scaling is applied during every iteration). Ignored otherwise.}

\item{memory}{The number of updates to store if using the \code{L-BFGS}
method. Ignored otherwise. Must be a positive integer.}

\item{cg_update}{Type of update to use for the \code{CG} method. Can be
one of \code{"FR"} (Fletcher-Reeves), \code{"PR"} (Polak-Ribiere),
\code{"PR+"} (Polak-Ribiere with a reset to steepest descent), \code{"HS"}
(Hestenes-Stiefel), or \code{"DY"} (Dai-Yuan). Ignored if \code{method} is
not \code{"CG"}.}

\item{nest_q}{Strong convexity parameter for the \code{"NAG"} method's
momentum term. Must take a value between 0 (strongly convex) and 1 (results
in steepest descent).Ignored unless the \code{method} is \code{"NAG"} and
\code{nest_convex_approx} is \code{FALSE}.}

\item{nest_convex_approx}{If \code{TRUE}, then use an approximation due to
Sutskever for calculating the momentum parameter in the NAG method. Only
applies if \code{method} is \code{"NAG"}.}

\item{nest_burn_in}{Number of iterations to wait before using a non-zero
momentum. Only applies if using the \code{"NAG"} method or setting the
\code{momentum_type} to "Nesterov".}

\item{use_nest_mu_zero}{If \code{TRUE}, then the momentum on iteration zero
is set to 0.4. Otherwise, it's zero. Applies only if
\code{nest_convex_approx} is \code{TRUE}.}

\item{step_up}{Value by which to increase the step size for the \code{"bold"}
step size method or the \code{"DBD"} method.}

\item{step_up_fun}{Operator to use when combining the current step size with
\code{step_up}. Can be one of \code{"*"} (to multiply the current step size
with \code{step_up}) or \code{"+"} (to add).}

\item{step_down}{Multiplier to reduce the step size by if using the \code{"DBD"}
method or the \code{"bold"} or \code{"back"} line search method. Should be
a positive value less than 1.}

\item{dbd_weight}{Weighting parameter used by the \code{"DBD"} method only, and
only if no momentum scheme is provided. Must be an integer between 0 and 1.}

\item{line_search}{Type of line search to use. See 'Details' of
\code{\link{mize}}.}

\item{c1}{Sufficient decrease parameter for Wolfe-type line searches. Should
be a value between 0 and 1.}

\item{c2}{Sufficient curvature parameter for line search for Wolfe-type line
searches. Should be a value between \code{c1} and 1.}

\item{step0}{Initial value for the line search on the first step. See
'Details' of \code{\link{mize}}.}

\item{step_next_init}{For Wolfe-type line searches only, how to initialize
the line search on iterations after the first. See 'Details' of
\code{\link{mize}}.}

\item{try_newton_step}{For Wolfe-type line searches only, try the
line step value of 1 as the initial step size whenever \code{step_next_init}
suggests a step size > 1. Defaults to \code{TRUE} for quasi-Newton methods
such as BFGS and L-BFGS, \code{FALSE} otherwise.}

\item{ls_max_fn}{Maximum number of function evaluations allowed during a
line search.}

\item{ls_max_gr}{Maximum number of gradient evaluations allowed during a
line search.}

\item{ls_max_fg}{Maximum number of function or gradient evaluations allowed
during a line search.}

\item{mom_type}{Momentum type, either \code{"classical"} or
\code{"nesterov"}.}

\item{mom_schedule}{Momentum schedule. See 'Details' of \code{\link{mize}}.}

\item{mom_init}{Initial momentum value.}

\item{mom_final}{Final momentum value.}

\item{mom_switch_iter}{For \code{mom_schedule} \code{"switch"} only, the
iteration when \code{mom_init} is changed to \code{mom_final}.}

\item{mom_linear_weight}{If \code{TRUE}, the gradient contribution to the
update is weighted using momentum contribution.}

\item{max_iter}{Maximum number of iterations the optimization will be carried
out over. Used only if \code{mom_schedule} is set to \code{"ramp"}.}

\item{restart}{Momentum restart type. Can be one of "fn" or "gr". See
'Details' of \code{\link{mize}}.}

\item{restart_wait}{Number of iterations to wait between restarts. Ignored
if \code{restart} is \code{NULL}.}

\item{par}{Initial values for the function to be optimized over. Optional.}

\item{fg}{Function and gradient list. See 'Details' of \code{\link{mize}}.
Optional.}
}
\description{
Factory function for creating a (possibly uninitialized) optimizer.
}
\details{
If the function to be optimized and starting point are not present at
creation time, then the optimizer should be initialized using
\code{\link{mize_init}} before being used with \code{\link{mize_step}}.

See the documentation to \code{\link{mize}} for an explanation of all
the parameters.

Details of the \code{fg} list containing the function to be optimized and
its gradient can be found in the 'Details' section of \code{\link{mize}}.
It is optional for this function, but if it is passed to this function,
along with the vector of initial values, \code{par}, the optimizer will be
returned already initialized for this function. Otherwise,
\code{\link{mize_init}} must be called before optimization begins.
}
\examples{
# Function to optimize and starting point
rosenbrock_fg <- list(
  fn = function(x) { 100 * (x[2] - x[1] * x[1]) ^ 2 + (1 - x[1]) ^ 2  },
  gr = function(x) { c( -400 * x[1] * (x[2] - x[1] * x[1]) - 2 * (1 - x[1]),
                         200 *        (x[2] - x[1] * x[1])) })
rb0 <- c(-1.2, 1)

# Create an optimizer and initialize it for use with the Rosenbrock function
opt <- make_mize(method = "L-BFGS", par = rb0, fg = rosenbrock_fg)

# Create optimizer without initialization
opt <- make_mize(method = "L-BFGS")

# Need to call mizer_init separately:
opt <- mize_init(opt, rb0, rosenbrock_fg)
}

